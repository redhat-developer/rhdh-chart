name: Nightly Test Charts

on:
  schedule:
    - cron: '38 21 * * *'
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: true

jobs:

  test-chart:
    name: Nightly Test
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6
        with:
          fetch-depth: 0

      - name: Set up Helm
        uses: azure/setup-helm@5119fcb9089d432beecbf79bb2c7915207344b78 # renovate: tag=v3.5
        with:
          version: v3.10.0

      - uses: actions/setup-python@83679a892e2d95755f2dac6acb0bfd1e9ac5d548 # v6
        with:
          python-version: 3.14

      - name: Set up chart-testing
        uses: helm/chart-testing-action@6ec842c01de15ebb84c8627d2744a0c2f2755c9f # v2.8.0
        with:
          version: '3.14.0'
          yamllint_version: '1.37.1'
          yamale_version: '6.0.0'

      - name: Remove unnecessary files to free up disk space
        uses: endersonmenezes/free-disk-space@e6ed9b02e683a3b55ed0252f1ee469ce3b39a885 # v3
        with:
          remove_android: true
          remove_dotnet: true
          remove_haskell: true
          rm_cmd: "rmz"

      - name: Add Helm Repositories
        run: |
          helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
          helm repo add bitnami https://charts.bitnami.com/bitnami
          helm repo add backstage https://backstage.github.io/charts
          helm repo update

      - name: Generate KinD Config
        run: |
          cat <<EOF > /tmp/kind-config.yaml
          apiVersion: kind.x-k8s.io/v1alpha4
          kind: Cluster
          nodes:
            - role: control-plane
              extraPortMappings:
                - containerPort: 80
                  hostPort: 80
                  protocol: TCP
                - containerPort: 443
                  hostPort: 443
                  protocol: TCP
          EOF

      - name: Create KIND Cluster
        uses: helm/kind-action@92086f6be054225fa813e0a4b13787fc9088faab # v1.13.0
        with:
          config: /tmp/kind-config.yaml

      - name: Create custom storage class
        run: |
          export defaultScProvisioner=$(kubectl get storageclass -o jsonpath='{.items[?(@.metadata.annotations.storageclass\.kubernetes\.io/is-default-class=="true")].provisioner}')
          if [[ -z "$defaultScProvisioner" ]]; then
            echo "No default storage class found or it has no provisioner. Exiting early because the test using the custom Storage Class will likely fail. Use a cluster that has a default storage class."
            exit 1
          fi
          echo "[INFO] defaultScProvisioner=$defaultScProvisioner"

          cat <<EOF | kubectl apply -f -
          apiVersion: storage.k8s.io/v1
          kind: StorageClass
          metadata:
            name: custom-sc
          # same provisioner as the one used by the default storage class on the cluster
          provisioner: $defaultScProvisioner
          reclaimPolicy: Delete
          volumeBindingMode: WaitForFirstConsumer
          EOF

          kubectl get storageclass custom-sc -o yaml

      - name: Install Ingress Controller
        run: |
          helm install ingress-nginx/ingress-nginx --generate-name \
            --set controller.service.type='NodePort' \
            --set controller.admissionWebhooks.enabled=false

      - name: Install Operator Lifecycle Manager (OLM)
        # In case we need to install additional Operators
        env:
          OLM_VERSION: "v0.31.0"
        run: |
          curl -L "https://github.com/operator-framework/operator-lifecycle-manager/releases/download/${OLM_VERSION}/install.sh" -o install-olm.sh
          chmod +x install-olm.sh
          ./install-olm.sh "${OLM_VERSION}"

      # https://issues.redhat.com/browse/RHIDP-7469 - minimal testing of the Orchestrator flavor.
      # The Orchestrator flavor requires installing the orchestrator-infra chart as a prerequisite,
      # but the OpenShift Serverless and Serverless Operators installed by this chart are available only on OCP (from the Red Hat Catalog).
      # For the simple testing that we are doing here on a vanilla K8s cluster, we only need both the Knative and SonataFlow CRDs.
      # TODO(rm3l): Update this when/if there is an upstream counterpart installable via OLM.
      - name: Install Knative and SonataFlow CRDs via the orchestrator-infra-chart as minimum prerequisite for testing the Orchestrator flavor
        env:
          SONATAFLOW_OPERATOR_VERSION: "10.1.0"
        run: |
          for crdDir in charts/orchestrator-infra/crds/*; do
            kubectl create -f "${crdDir}"
          done
          kubectl create -f "https://github.com/apache/incubator-kie-tools/releases/download/${SONATAFLOW_OPERATOR_VERSION}/apache-kie-${SONATAFLOW_OPERATOR_VERSION}-incubating-sonataflow-operator.yaml"

      - name: Run chart-testing (install)
        run: |
          EXTRA_ARGS=(
            "--set upstream.backstage.image.repository=rhdh-community/rhdh"
            "--set upstream.backstage.image.tag=next"
            "--set upstream.backstage.image.pullPolicy=Always"
            "--set route.enabled=false"
            "--set upstream.ingress.enabled=true"
            "--set global.host=rhdh.127.0.0.1.sslip.io"
          )
          ct install \
            --debug \
            --config ct-install.yaml \
            --upgrade \
            --target-branch main \
            --helm-extra-set-args="${EXTRA_ARGS[*]}"
